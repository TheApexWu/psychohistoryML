{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PsychohistoryML: Methodology Fixes (Notebook 11)\n",
    "\n",
    "**Objective**: Fix data leakage issues and implement advanced survival analysis.\n",
    "\n",
    "## Issues Fixed\n",
    "\n",
    "1. **Data Leakage**: Previous notebooks fit StandardScaler and PCA on full data before cross-validation\n",
    "2. **Hyperparameter Tuning**: No systematic tuning of RF/XGB parameters\n",
    "3. **Survival Analysis**: Basic Cox PH only; adding competing risks, time-varying effects\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Data leakage inflates performance estimates by 1-5%. When you fit a scaler on the full dataset,\n",
    "information from the test set \"leaks\" into the training process via the mean/std calculations.\n",
    "\n",
    "**Leaky approach (previous notebooks):**\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Leak! Uses ALL data\n",
    "cross_val_score(model, X_scaled, y)  # Scores are inflated\n",
    "```\n",
    "\n",
    "**Correct approach (this notebook):**\n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "cross_val_score(pipeline, X, y)  # Scaler refit in each fold\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn - proper pipeline approach\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, StratifiedKFold, GridSearchCV, \n",
    "    LeaveOneGroupOut, cross_val_predict\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# Survival analysis\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter, KaplanMeierFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Setup\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "Path('figures').mkdir(exist_ok=True)\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset from NB07\n",
    "df = pd.read_csv('models/equinox_with_religion.csv', index_col=0)\n",
    "print(f'Loaded {len(df)} polities')\n",
    "\n",
    "# Define features\n",
    "HIERARCHY_COLS = ['Settlement hierarchy', 'Administrative levels', \n",
    "                  'Military levels', 'Religious levels']\n",
    "WARFARE_COLS = ['total_warfare_tech']\n",
    "RELIGION_COLS = ['total_rel']\n",
    "\n",
    "ALL_FEATURES = HIERARCHY_COLS + WARFARE_COLS + RELIGION_COLS\n",
    "\n",
    "# Target: short duration (< median)\n",
    "DURATION_THRESHOLD = df['duration_years'].median()\n",
    "df['unstable'] = (df['duration_years'] < DURATION_THRESHOLD).astype(int)\n",
    "\n",
    "print(f'\\nDuration threshold: {DURATION_THRESHOLD:.0f} years (median)')\n",
    "print(f'Class balance: {df[\"unstable\"].mean():.1%} unstable')\n",
    "\n",
    "# Era for LOEO validation\n",
    "df['era_code'] = df['era'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Fix Data Leakage: Pipeline-Based Cross-Validation\n",
    "\n",
    "### 2.1 Compare Leaky vs Correct Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df[ALL_FEATURES].values\n",
    "y = df['unstable'].values\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print('Comparing leaky vs correct approaches...')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAKY APPROACH (what we did before)\n",
    "# This is WRONG - scaler sees all data before CV\n",
    "\n",
    "scaler_leaky = StandardScaler()\n",
    "X_scaled_leaky = scaler_leaky.fit_transform(X)  # LEAK!\n",
    "\n",
    "rf_leaky = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5, \n",
    "    random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "scores_leaky = cross_val_score(rf_leaky, X_scaled_leaky, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f'LEAKY APPROACH (old method):')\n",
    "print(f'  AUC: {scores_leaky.mean():.3f} ± {scores_leaky.std():.3f}')\n",
    "print(f'  Range: [{scores_leaky.min():.3f}, {scores_leaky.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT APPROACH: Pipeline\n",
    "# Scaler is refit inside each CV fold\n",
    "\n",
    "pipeline_correct = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5,\n",
    "        random_state=42, class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "scores_correct = cross_val_score(pipeline_correct, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f'\\nCORRECT APPROACH (pipeline):')\n",
    "print(f'  AUC: {scores_correct.mean():.3f} ± {scores_correct.std():.3f}')\n",
    "print(f'  Range: [{scores_correct.min():.3f}, {scores_correct.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate leakage impact\n",
    "leakage_impact = scores_leaky.mean() - scores_correct.mean()\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'LEAKAGE IMPACT: {leakage_impact:+.3f} AUC')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "if leakage_impact > 0.01:\n",
    "    print(f'\\n⚠️  Leakage inflated performance by {leakage_impact:.1%}')\n",
    "    print(f'    Old notebooks reported inflated AUC values')\n",
    "else:\n",
    "    print(f'\\n✓ Leakage impact minimal ({leakage_impact:.1%})')\n",
    "    print(f'  RF is somewhat robust to scaling leakage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pipeline with PCA (Full Correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with BOTH scaling AND PCA inside CV\n",
    "# This is the fully correct approach\n",
    "\n",
    "pipeline_full = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5,\n",
    "        random_state=42, class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Only use hierarchy features for PCA (matches original design)\n",
    "X_hier = df[HIERARCHY_COLS].values\n",
    "\n",
    "scores_full = cross_val_score(pipeline_full, X_hier, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print('Pipeline with PCA (hierarchy features only):')\n",
    "print(f'  AUC: {scores_full.mean():.3f} ± {scores_full.std():.3f}')\n",
    "\n",
    "# Compare to old NB04 result (0.713 with median threshold)\n",
    "print(f'\\nComparison to NB04 (leaky):')\n",
    "print(f'  NB04 reported: 0.713')\n",
    "print(f'  Corrected:     {scores_full.mean():.3f}')\n",
    "print(f'  Difference:    {scores_full.mean() - 0.713:+.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hyperparameter Tuning with Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [3, 5, 7, None],\n",
    "    'rf__min_samples_split': [5, 10, 20]\n",
    "}\n",
    "\n",
    "# Inner CV for hyperparameter selection\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Outer CV for performance estimation\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print('Running nested cross-validation with hyperparameter tuning...')\n",
    "print('This may take a minute...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for grid search\n",
    "pipeline_tune = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Grid search with inner CV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_tune, param_grid,\n",
    "    cv=inner_cv, scoring='roc_auc',\n",
    "    n_jobs=-1, refit=True\n",
    ")\n",
    "\n",
    "# Nested CV: outer loop for unbiased performance estimate\n",
    "nested_scores = cross_val_score(grid_search, X, y, cv=outer_cv, scoring='roc_auc')\n",
    "\n",
    "print(f'\\nNested CV Results (with hyperparameter tuning):')\n",
    "print(f'  AUC: {nested_scores.mean():.3f} ± {nested_scores.std():.3f}')\n",
    "print(f'  Range: [{nested_scores.min():.3f}, {nested_scores.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final grid search to get best params\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f'\\nBest hyperparameters:')\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f'  {param}: {value}')\n",
    "print(f'\\nBest inner CV score: {grid_search.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Leave-One-Era-Out (LOEO) Validation - Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOEO: Tests temporal generalization\n",
    "# Train on 3 eras, test on the held-out era\n",
    "\n",
    "groups = df['era_code'].values\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Use best pipeline from tuning\n",
    "best_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        **{k.replace('rf__', ''): v for k, v in grid_search.best_params_.items()},\n",
    "        random_state=42, class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "loeo_scores = []\n",
    "era_names = df['era'].unique()\n",
    "\n",
    "print('Leave-One-Era-Out Cross-Validation:')\n",
    "print('=' * 60)\n",
    "\n",
    "for train_idx, test_idx in logo.split(X, y, groups):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    y_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Get held-out era name\n",
    "    held_out_era = df.iloc[test_idx]['era'].iloc[0]\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        loeo_scores.append(auc)\n",
    "        print(f'  Held out: {held_out_era:35} AUC = {auc:.3f} (n={len(test_idx)})')\n",
    "    except ValueError:\n",
    "        print(f'  Held out: {held_out_era:35} AUC = N/A (single class)')\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'LOEO Mean AUC: {np.mean(loeo_scores):.3f} ± {np.std(loeo_scores):.3f}')\n",
    "print(f'\\nComparison:')\n",
    "print(f'  Standard 5-fold CV: {nested_scores.mean():.3f}')\n",
    "print(f'  LOEO (temporal):    {np.mean(loeo_scores):.3f}')\n",
    "print(f'  Gap:                {nested_scores.mean() - np.mean(loeo_scores):+.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. Advanced Survival Analysis\n\n### Mathematical Background\n\n#### Cox Proportional Hazards (Baseline)\nCox models hazard multiplicatively:\n\n$$h(t|X) = h_0(t) \\cdot \\exp(\\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p)$$\n\n- $h_0(t)$ = baseline hazard (unspecified)\n- $\\beta$ = coefficients (CONSTANT over time)\n- **Key assumption**: Hazard ratio between any two polities is constant\n\n#### Weibull AFT (Accelerated Failure Time)\nModels survival time directly:\n\n$$\\log(T) = \\mu + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\sigma W$$\n\nWhere $W \\sim$ Extreme Value distribution. The Weibull survival/hazard:\n\n$$S(t) = \\exp\\left(-\\left(\\frac{t}{\\lambda}\\right)^\\rho\\right) \\qquad h(t) = \\frac{\\rho}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{\\rho-1}$$\n\n**Shape parameter $\\rho$ interpretation:**\n- $\\rho < 1$: Decreasing hazard (\"infant mortality\" - early years dangerous)\n- $\\rho = 1$: Constant hazard (exponential - age doesn't matter)\n- $\\rho > 1$: Increasing hazard (\"aging\" - older = more fragile)\n\n**Coefficient interpretation:** $\\exp(\\beta)$ = time multiplier\n- $\\beta > 0 \\rightarrow \\exp(\\beta) > 1 \\rightarrow$ longer survival (protective)\n- $\\beta < 0 \\rightarrow \\exp(\\beta) < 1 \\rightarrow$ shorter survival (risk factor)\n\n#### Aalen Additive Model\nAllows coefficients to vary over time:\n\n$$h(t|X) = \\beta_0(t) + \\beta_1(t)X_1 + \\beta_2(t)X_2 + ... + \\beta_p(t)X_p$$\n\nEstimates cumulative coefficients: $B(t) = \\int_0^t \\beta(s) ds$\n\n- **Slope of $B(t)$** = effect strength at time $t$\n- **Rising $B(t)$** = effect accumulates over polity lifetime\n- **Flat $B(t)$** = Cox assumption holds (constant effect)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare survival data\n",
    "survival_features = ['PC1_hier', 'PC2_hier', 'PC3_hier', \n",
    "                     'total_warfare_tech', 'total_rel']\n",
    "\n",
    "surv_df = df[['duration_years'] + survival_features].copy()\n",
    "surv_df['event'] = 1  # All polities ended\n",
    "surv_df = surv_df.rename(columns={'duration_years': 'T'})\n",
    "\n",
    "# Standardize features\n",
    "for col in survival_features:\n",
    "    surv_df[col] = (surv_df[col] - surv_df[col].mean()) / surv_df[col].std()\n",
    "\n",
    "surv_df = surv_df.dropna()\n",
    "print(f'Survival analysis dataset: {len(surv_df)} polities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weibull AFT model\n",
    "# Unlike Cox, this is fully parametric and models duration directly\n",
    "\n",
    "weibull = WeibullAFTFitter()\n",
    "weibull.fit(surv_df, duration_col='T', event_col='event')\n",
    "\n",
    "print('Weibull Accelerated Failure Time Model')\n",
    "print('=' * 60)\n",
    "print('\\nInterpretation: Positive coef = LONGER survival (protective)')\n",
    "print('              Negative coef = SHORTER survival (destabilizing)\\n')\n",
    "weibull.print_summary(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Cox vs Weibull\n",
    "cox = CoxPHFitter()\n",
    "cox.fit(surv_df, duration_col='T', event_col='event')\n",
    "\n",
    "print('Model Comparison:')\n",
    "print(f'  Cox PH C-index:  {cox.concordance_index_:.3f}')\n",
    "print(f'  Weibull C-index: {weibull.concordance_index_:.3f}')\n",
    "\n",
    "print(f'\\nWeibull shape parameter (rho): {weibull.summary.loc[(\"rho_\", \"_intercept\"), \"coef\"]:.3f}')\n",
    "print('  rho > 1: Hazard increases over polity lifetime (aging effect)')\n",
    "print('  rho < 1: Hazard decreases (infant mortality, survivors are stronger)')\n",
    "print('  rho = 1: Constant hazard (exponential distribution)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Time-Varying Coefficients (Aalen Additive Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import AalenAdditiveFitter\n",
    "\n",
    "# Aalen model allows coefficients to vary over time\n",
    "# Tests: Does the effect of complexity change as polities age?\n",
    "\n",
    "aalen = AalenAdditiveFitter(coef_penalizer=1.0)  # Regularization for stability\n",
    "aalen.fit(surv_df, duration_col='T', event_col='event')\n",
    "\n",
    "print('Aalen Additive Model (time-varying coefficients)')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-varying effects\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "aalen.plot(ax=axes[0], columns=['PC1_hier'])\n",
    "axes[0].set_title('PC1 (Complexity) Effect Over Time')\n",
    "axes[0].set_xlabel('Polity Duration (years)')\n",
    "\n",
    "aalen.plot(ax=axes[1], columns=['total_rel'])\n",
    "axes[1].set_title('Religion Effect Over Time')\n",
    "axes[1].set_xlabel('Polity Duration (years)')\n",
    "\n",
    "aalen.plot(ax=axes[2], columns=['total_warfare_tech'])\n",
    "axes[2].set_title('Warfare Effect Over Time')\n",
    "axes[2].set_xlabel('Polity Duration (years)')\n",
    "\n",
    "aalen.plot(ax=axes[3], columns=['PC2_hier'])\n",
    "axes[3].set_title('PC2 Effect Over Time')\n",
    "axes[3].set_xlabel('Polity Duration (years)')\n",
    "\n",
    "aalen.plot(ax=axes[4], columns=['PC3_hier'])\n",
    "axes[4].set_title('PC3 Effect Over Time')\n",
    "axes[4].set_xlabel('Polity Duration (years)')\n",
    "\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Aalen Model: How Effects Change Over Polity Lifetime', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/11_aalen_time_varying.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nInterpretation:')\n",
    "print('  - Flat line: Constant effect (Cox assumption holds)')\n",
    "print('  - Upward slope: Effect strengthens over polity lifetime')\n",
    "print('  - Downward slope: Effect weakens over polity lifetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Era-Stratified Survival Curves with Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Kaplan-Meier by era with CIs\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "era_order = ['Ancient (pre-500 BCE)', 'Classical (500 BCE-500 CE)', \n",
    "             'Medieval (500-1500 CE)', 'Early Modern (1500+ CE)']\n",
    "\n",
    "era_colors = {\n",
    "    'Ancient (pre-500 BCE)': '#8B4513',\n",
    "    'Classical (500 BCE-500 CE)': '#2E8B57',\n",
    "    'Medieval (500-1500 CE)': '#4169E1',\n",
    "    'Early Modern (1500+ CE)': '#DC143C'\n",
    "}\n",
    "\n",
    "for era in era_order:\n",
    "    if era not in df['era'].values:\n",
    "        continue\n",
    "    mask = df['era'] == era\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df.loc[mask, 'duration_years'], \n",
    "            label=f'{era} (n={mask.sum()}, median={df.loc[mask, \"duration_years\"].median():.0f}y)')\n",
    "    kmf.plot_survival_function(ax=ax, color=era_colors[era], ci_show=True)\n",
    "\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='50% survival')\n",
    "ax.set_xlabel('Duration (years)', fontsize=12)\n",
    "ax.set_ylabel('Survival Probability', fontsize=12)\n",
    "ax.set_title('Kaplan-Meier Survival Curves by Era (with 95% CI)', fontsize=14)\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/11_km_by_era_ci.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary: Corrected Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('NOTEBOOK 11 SUMMARY: Methodology Fixes')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'''\n",
    "1. DATA LEAKAGE FIX\n",
    "   Old (leaky) approach:  AUC = {scores_leaky.mean():.3f}\n",
    "   New (correct) approach: AUC = {scores_correct.mean():.3f}\n",
    "   Leakage impact:        {leakage_impact:+.3f}\n",
    "\n",
    "2. HYPERPARAMETER TUNING (Nested CV)\n",
    "   Tuned AUC: {nested_scores.mean():.3f} ± {nested_scores.std():.3f}\n",
    "   Best params: {grid_search.best_params_}\n",
    "\n",
    "3. TEMPORAL GENERALIZATION (LOEO)\n",
    "   Standard CV:  {nested_scores.mean():.3f}\n",
    "   LOEO:         {np.mean(loeo_scores):.3f}\n",
    "   Gap:          {nested_scores.mean() - np.mean(loeo_scores):+.3f}\n",
    "   → Model struggles to generalize across historical eras\n",
    "\n",
    "4. SURVIVAL ANALYSIS\n",
    "   Cox C-index:     {cox.concordance_index_:.3f}\n",
    "   Weibull C-index: {weibull.concordance_index_:.3f}\n",
    "   \n",
    "5. KEY INSIGHT\n",
    "   After fixing methodology issues:\n",
    "   - Performance estimates are slightly lower (more honest)\n",
    "   - LOEO gap confirms era-specific patterns\n",
    "   - Time-varying effects (Aalen) reveal dynamics\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corrected results\n",
    "results = {\n",
    "    'metric': ['5-fold CV (leaky)', '5-fold CV (correct)', 'Nested CV (tuned)', 'LOEO', 'Cox C-index', 'Weibull C-index'],\n",
    "    'value': [scores_leaky.mean(), scores_correct.mean(), nested_scores.mean(), np.mean(loeo_scores), cox.concordance_index_, weibull.concordance_index_],\n",
    "    'std': [scores_leaky.std(), scores_correct.std(), nested_scores.std(), np.std(loeo_scores), np.nan, np.nan]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('models/corrected_results.csv', index=False)\n",
    "\n",
    "print('Saved: models/corrected_results.csv')\n",
    "print('\\nFigures saved:')\n",
    "print('  figures/11_aalen_time_varying.png')\n",
    "print('  figures/11_km_by_era_ci.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Implications for Future Work\n",
    "\n",
    "### What We Fixed\n",
    "1. **Data leakage**: Scaler/PCA now refit in each CV fold\n",
    "2. **Hyperparameter tuning**: Systematic grid search with nested CV\n",
    "3. **Temporal validation**: LOEO shows model doesn't generalize across eras\n",
    "\n",
    "### What This Means\n",
    "- Previous AUC estimates were ~1-3% inflated\n",
    "- The LOEO gap (CV vs temporal) is the **real story**\n",
    "- Era-specific patterns dominate; no universal \"laws\"\n",
    "\n",
    "### For Future Work (with CrisisDB)\n",
    "- Apply same pipeline-based approach from the start\n",
    "- Use nested CV for hyperparameter tuning\n",
    "- Report LOEO prominently (temporal generalization is key)\n",
    "- Consider time-varying effects (Aalen model)\n",
    "- Test Turchin's Scale-Comp framework properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}